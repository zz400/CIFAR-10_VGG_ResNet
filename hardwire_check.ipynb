{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKXenUTrHYbV"
   },
   "source": [
    "### Basic knowledge about GPU\n",
    "- Colab uses Tesla K80, if lucky, you can get Tesla P100 or T4.\n",
    "- Kaggle uses Tesla P100.\n",
    "- Both Colab and Kaggle only provide single core cpu (if you want to using ImageGenerator, one core is very slow).\n",
    "- Performance benchmark: 1080Ti = (2 ~ 3)x K80; 1080Ti = P100\n",
    "- V100 > P100 = 1080Ti > T4 > K80\n",
    "\n",
    "### A great artical comparing the specs, performances, and prices of Colab, AWS, Google Cloud, etc.\n",
    "https://towardsdatascience.com/maximize-your-gpu-dollars-a9133f4e546a\n",
    "\n",
    "### Google Cloud: $300 free, and how to setup:\n",
    "https://medium.com/@jamsawamsa/running-a-google-cloud-gpu-for-fast-ai-for-free-5f89c707bae6\n",
    "\n",
    "or even $500 free credit??\n",
    "\n",
    "https://codefresh.io/google-cloud/?utm_source=Google&utm_medium=Search&utm_campaign=KubGCredit2&gclid=Cj0KCQiAw4jvBRCJARIsAHYewPPTDCKVx9nmfxO1TKL-6a-XOg3NZamNFVsGLj_9MlclxbajHWNcDq8aAp9lEALw_wcB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fCRVyw-Nhyo"
   },
   "source": [
    "# Check CPU, Memory, Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "jMtNLViDfdT8",
    "outputId": "3e610321-10e1-4b43-c104-797fe639fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "Socket(s):             1\n",
      "Thread(s) per core:    2\n",
      "L3 cache:              56320K\n",
      "CPU MHz:               2200.000\n",
      "MemAvailable:   29784976 kB\n",
      "Avail\n",
      "74G\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "\n",
    "!lscpu |grep 'Model name'\n",
    "\n",
    "#no.of sockets i.e available slots for physical processors\n",
    "!lscpu | grep 'Socket(s):'\n",
    "\n",
    "#no.of threads each core is having\n",
    "!lscpu | grep 'Thread(s) per core'\n",
    "\n",
    "!lscpu | grep 'L3 cache'\n",
    "\n",
    "!lscpu | grep MHz\n",
    "\n",
    "!cat /proc/meminfo | grep 'MemAvailable'\n",
    "\n",
    "!df -h / | awk '{print $4}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBAZXd8B8lxP"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eWSYD4Hp-U3I",
    "outputId": "165c8078-9c71-486a-fa8e-c8dd68217776"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "g2hBsn6QB_kx",
    "outputId": "3a35d0f6-a580-433f-8b5c-7f9199a0707b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "True\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "colab_type": "code",
    "id": "zswmWhfIDTDT",
    "outputId": "5b535a4f-2bcd-4518-f4a8-696491511974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in ./.local/lib/python3.5/site-packages\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: humanize in ./.local/lib/python3.5/site-packages\n",
      "--------------------\n",
      "GPU number: 1\n",
      "Gen RAM Free: 30.5 GB  | Proc size: 186.0 MB\n",
      "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n",
      "GPU Name: Tesla P100-PCIE-16GB\n",
      "{\n",
      "  \"memoryFree\": 16280.0,\n",
      "  \"name\": \"Tesla P100-PCIE-16GB\",\n",
      "  \"display_mode\": \"Enabled\",\n",
      "  \"load\": 0.0,\n",
      "  \"memoryTotal\": 16280.0,\n",
      "  \"temperature\": 41.0,\n",
      "  \"display_active\": \"Disabled\",\n",
      "  \"memoryUsed\": 0.0,\n",
      "  \"uuid\": \"GPU-3b3ea54c-a961-24d4-5942-133fe25ad1b9\",\n",
      "  \"driver\": \"410.104\",\n",
      "  \"memoryUtil\": 0.0,\n",
      "  \"id\": 0,\n",
      "  \"serial\": \"0324317003687\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gputil\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip3 install psutil\n",
    "!pip3 install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "import json\n",
    "\n",
    "print('--------------------')\n",
    "GPUs = GPU.getGPUs()\n",
    "print('GPU number: {}'.format(len(GPUs)))\n",
    "\n",
    "if len(GPUs) > 0:\n",
    "    gpu = GPUs[0]\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \"\\\n",
    "          + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\"\\\n",
    "          .format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "    print(\"GPU Name: \" + gpu.name)\n",
    "    print(json.dumps(gpu.__dict__, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "Xe7349paNvbY",
    "outputId": "72f7a7a2-12fe-402b-c99f-7c5afb3cc01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  3 06:07:57 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    36W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGk3fUReY6Ol"
   },
   "source": [
    "# CNN Benchmark Test\n",
    "\n",
    "### Model: ResNet with 17 Conv2D layers. \n",
    "### Dataset: Cifar-10\n",
    "\n",
    "### On Colab, GPU = K80:\n",
    "- w/o image augmentation: 50s/epoch\n",
    "- w/  image augmentation (1 cpu): 150s/epoch\n",
    "\n",
    "### On Colab, GPU = P100:\n",
    "- w/o image augmentation: 13s/epoch\n",
    "- w/  image augmentation (1 cpu): 90s/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuJW3PgiZBNM"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "1Yk6ntTwZQfN",
    "outputId": "b0bdead7-55f2-4bf5-9914-d06254ce1baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 19s 373us/step - loss: 2.0436 - accuracy: 0.2921 - val_loss: 4.7049 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.5305 - accuracy: 0.4346 - val_loss: 6.8288 - val_accuracy: 0.1000\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/2\n",
      "48/49 [============================>.] - ETA: 0s - loss: 1.5769 - accuracy: 0.4255\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 1.5752 - accuracy: 0.4257 - val_loss: 6.7191 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 1.4619 - accuracy: 0.4663 - val_loss: 6.9454 - val_accuracy: 0.0997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras.models import Model, Sequential \n",
    "# from tensorflow.keras.layers import Input, Conv2D, Dense\n",
    "# from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "# from tensorflow.keras.layers import Add, Activation, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras import models\n",
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Input, Conv2D, Dense\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from keras.layers import Add, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "num_classes = 10\n",
    "\n",
    "# Convert y_train and y_test into one-hot labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test  = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Rescale X_train and X_test\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "def identity_block(X, f, filters, shortcut_on, dropout_on, dropout_rates, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block \n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the Conv kernel for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the Conv layers of the main path\n",
    "    shortcut_on -- boolean, with shortcut or not\n",
    "    dropout_on -- boolean, with dropout layers or not\n",
    "    dropout_rates -- python list of float, defining the dropout_rate after each Conv layer\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network    \n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \n",
    "    Note:\n",
    "    the input channel number and the output channel number (filters[2]) must be the same.\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2 = filters\n",
    "\n",
    "    # Retrieve dropout_rates\n",
    "    D1, D2 = dropout_rates\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(3,3), strides=(1,1), padding='same', name=conv_name_base+'2a')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    if dropout_on:\n",
    "      X = Dropout(D1)(X)\n",
    "    \n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(1,1), padding='same', name=conv_name_base+'2b')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'2b')(X)\n",
    "    ##### MAIN PATH END #####\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    if dropout_on:\n",
    "        X_shortcut = Dropout(D2)(X_shortcut)  # Shortcut with dropout performs better\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    if shortcut_on:\n",
    "        X = Add()([X, X_shortcut])    \n",
    "\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def convolutional_block(X, f, filters, stride, shortcut_on, dropout_on, dropout_rates, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional_block block \n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the Conv kernel for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the Conv layers of the main path\n",
    "    stride -- Integer, specifying the stride to be used\n",
    "    shortcut_on -- boolean, with shortcut or not\n",
    "    dropout_on -- boolean, with dropout layers or not\n",
    "    dropout_rates -- python list of float, defining the dropout_rate after each Conv layer\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2 = filters\n",
    "\n",
    "    # Retrieve dropout_rates\n",
    "    D1, D2 = dropout_rates\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(3,3), strides=(stride,stride), padding='same', name=conv_name_base+'2a')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    if dropout_on:\n",
    "        X = Dropout(D1)(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(1,1), padding='same', name=conv_name_base+'2b')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'2b')(X)\n",
    "    ##### MAIN PATH END #####\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters=F2, kernel_size=(1,1), strides=(stride,stride), padding='valid', name=conv_name_base+'1')(X_shortcut)\n",
    "    if dropout_on:\n",
    "        X_shortcut = Dropout(D2)(X_shortcut)  # Shortcut with dropout performs better\n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    if shortcut_on:\n",
    "        X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def ResNet(shortcut_on, dropout_on, dropout_rates, input_shape=(32, 32, 3), classes=10):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "    shortcut_on -- boolean, with shortcut or not\n",
    "    dropout_on -- boolean, with dropout layers or not\n",
    "    dropout_rates -- python list of float, defining the dropout_rate after each Conv layer\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((1, 1))(X_input)  # output: 34 x 34 x 3\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(32, (3, 3), strides=(1, 1), activation='relu', name='conv0')(X)  # output: 32 x 32 x 32\n",
    "    X = BatchNormalization(name='bn_conv0')(X)\n",
    "    X = identity_block(X, 3, [32, 32], shortcut_on, dropout_on, dropout_rates, stage=1, block='a')    # output: 32 x 32 x 32\n",
    "    X = MaxPooling2D((2, 2))(X)   # output: 16 x 16 x 32\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, 3, [64, 64], 1, shortcut_on, dropout_on, dropout_rates, stage=2, block='a')  \n",
    "    X = identity_block(X, 3, [64, 64], shortcut_on, dropout_on, dropout_rates, stage=2, block='b')    # output: 16 x 16 x 64\n",
    "    X = MaxPooling2D((2, 2))(X)   # output: 8 x 8 x 64\n",
    "\n",
    "    # Stage 3 \n",
    "    X = convolutional_block(X, 3, [128, 128], 1, shortcut_on, dropout_on, dropout_rates, stage=3, block='a')  \n",
    "    X = identity_block(X, 3, [128, 128], shortcut_on, dropout_on, dropout_rates, stage=3, block='b')    # output: 8 x 8 x 128\n",
    "    X = MaxPooling2D((2, 2))(X)   # output: 4 x 4 x 128\n",
    "\n",
    "    # Stage 4 \n",
    "    X = convolutional_block(X, 3, [256, 256], 1, shortcut_on, dropout_on, dropout_rates, stage=4, block='a')  \n",
    "    X = identity_block(X, 3, [256, 256], shortcut_on, dropout_on, dropout_rates, stage=4, block='b')    # output: 4 x 4 x 256\n",
    "    X = MaxPooling2D((2, 2))(X)   # output: 2 x 2 x 256\n",
    "\n",
    "    # Fully connected layers\n",
    "    X = Flatten()(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(units=1024, activation='relu', name='fc1')(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(units=1024, activation='relu', name='fc2')(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(units=512, activation='relu', name='fc3')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Dense(units=classes, activation='softmax', name='fc_out')(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run(cnn_model, X_train, y_train, batch_size, epochs, data_augmentation, validation_data):\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = cnn_model.fit(X_train,y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=validation_data,\n",
    "                                shuffle=True)\n",
    "\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.2,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,  # set range for random shear\n",
    "            zoom_range=0.2,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split=0.0)\n",
    "\n",
    "        # Compute quantities required for feature-wise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(X_train)\n",
    "\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        history = cnn_model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                          epochs=epochs,\n",
    "                                          validation_data=validation_data,\n",
    "                                          workers=8,\n",
    "                                          use_multiprocessing=True)\n",
    "\n",
    "\n",
    "shortcut_on = True\n",
    "dropout_on = True\n",
    "dropout_rates = [0.3, 0.2]\n",
    "opt = Adam(learning_rate=0.001) #RMSprop(lr=0.001)\n",
    "\n",
    "cnn_model = ResNet(shortcut_on, dropout_on, dropout_rates)\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Run w/o data augmentation\n",
    "data_augmentation = False\n",
    "batch_size = 1024\n",
    "epochs = 2\n",
    "validation_data=(X_test, y_test)\n",
    "run(cnn_model, X_train, y_train, batch_size, epochs, data_augmentation, validation_data)\n",
    "\n",
    "# Run with data augmentation (Note: ImageDataGenerator runs on CPU, so it's slow.)\n",
    "data_augmentation = True\n",
    "batch_size = 1024\n",
    "epochs = 2\n",
    "validation_data=(X_test, y_test)\n",
    "run(cnn_model, X_train, y_train, batch_size, epochs, data_augmentation, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hardwire_check.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
